{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3501ff6d",
      "metadata": {
        "id": "3501ff6d"
      },
      "source": [
        "# ✅ Pré-processamento\n",
        "Este notebook carrega e normaliza automaticamente duas bases:\n",
        "- `VGG19_256_MAX.csv`\n",
        "- `VGG19_256_MAX_PCA.csv`\n",
        "\n",
        "Todas as etapas dos comitês (Bagging, Boosting, Random Forest) são executadas nas **duas bases**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "912e2365",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "912e2365",
        "outputId": "5f575dab-5b25-47f8-8c39-f4463d90dda4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 Normalizando: VGG19_256_MAX.csv\n",
            "✅ Base salva como: VGG19_256_MAX_NORMALIZADA.csv\n",
            "\n",
            "🔄 Normalizando: VGG19_256_MAX_PCA.csv\n",
            "✅ Base salva como: VGG19_256_MAX_PCA_NORMALIZADA.csv\n",
            "\n",
            "🎉 Todas as bases foram normalizadas, salvas e estão prontas para uso.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Bases a normalizar\n",
        "bases = [\n",
        "    'VGG19_256_MAX.csv',\n",
        "    'VGG19_256_MAX_PCA.csv'\n",
        "]\n",
        "\n",
        "# Dicionário para armazenar (X_normalizado, y)\n",
        "bases_normalizadas = {}\n",
        "\n",
        "for base in bases:\n",
        "    print(f\"\\n🔄 Normalizando: {base}\")\n",
        "\n",
        "    # Carregar base\n",
        "    df = pd.read_csv(base)\n",
        "\n",
        "    # Separar atributos e classe\n",
        "    X = df.drop(columns=['classe'])\n",
        "    y = df['classe'].astype(str)  # <- IMPORTANTE para evitar erros com tipos mistos\n",
        "\n",
        "    # Normalizar os atributos\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Salvar em novo DataFrame\n",
        "    df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "    df_final = pd.concat([df_scaled, y], axis=1)\n",
        "\n",
        "    # Salvar CSV normalizado\n",
        "    nome_saida = base.replace('.csv', '_NORMALIZADA.csv')\n",
        "    df_final.to_csv(nome_saida, index=False)\n",
        "    print(f\"✅ Base salva como: {nome_saida}\")\n",
        "\n",
        "    # Armazenar para uso posterior\n",
        "    bases_normalizadas[base.replace('.csv', '')] = (df_scaled, y)\n",
        "\n",
        "print(\"\\n🎉 Todas as bases foram normalizadas, salvas e estão prontas para uso.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4f69e21",
      "metadata": {
        "id": "f4f69e21"
      },
      "source": [
        "# 🔷 BAGGING Experimentos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "estimadores = [\n",
        "    ('Decision Tree', DecisionTreeClassifier()),\n",
        "    ('k-NN', KNeighborsClassifier()),\n",
        "    ('Naive Bayes', GaussianNB()),\n",
        "    ('MLP', MLPClassifier(max_iter=500))\n",
        "]\n",
        "\n",
        "n_estimators_list = [10, 20, 30]\n",
        "resultados = []\n",
        "\n",
        "for nome_base, (X, y) in bases_normalizadas.items():\n",
        "    for nome_clf, clf in estimadores:\n",
        "        for n in n_estimators_list:\n",
        "            model = BaggingClassifier(estimator=clf, n_estimators=n, random_state=1)\n",
        "\n",
        "            # 10-fold cross-validation\n",
        "            acc_cv = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
        "            y_pred_cv = cross_val_predict(model, X, y, cv=10)\n",
        "            cm_cv = confusion_matrix(y, y_pred_cv)\n",
        "\n",
        "            # Split 70/30\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred_split = model.predict(X_test)\n",
        "            acc_split = accuracy_score(y_test, y_pred_split)\n",
        "            cm_split = confusion_matrix(y_test, y_pred_split)\n",
        "\n",
        "            # Salvar resultados\n",
        "            resultados.append({\n",
        "                'Base': nome_base,\n",
        "                'Classificador': nome_clf,\n",
        "                'n_estimators': n,\n",
        "                'Acuracia_10fold': round(np.mean(acc_cv)*100, 2),\n",
        "                'Desvio_10fold': round(np.std(acc_cv)*100, 2),\n",
        "                'Matriz_Confusao_10fold': cm_cv.tolist(),\n",
        "                'Acuracia_Split7030': round(acc_split*100, 2),\n",
        "                'Matriz_Confusao_Split7030': cm_split.tolist()\n",
        "            })\n",
        "\n",
        "# Exportar para CSV\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "df_resultados.to_csv('Resultados_Bagging.csv', index=False)\n",
        "\n",
        "print(\"✅ Resultados salvos em 'Resultados_Bagging.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339ed62a-720b-44e0-ce4e-34f8f5e9663a",
        "id": "uFiESS_yN8T2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Resultados salvos em 'Resultados_Bagging.csv'\n"
          ]
        }
      ],
      "id": "uFiESS_yN8T2"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Simule ou carregue seu dicionário com as bases já normalizadas\n",
        "# bases_normalizadas = {'nome_base': (X, y)}\n",
        "\n",
        "# Parâmetros\n",
        "max_features_list = [0.3, 0.5, 0.8]\n",
        "n_estimators_list = [10, 20, 30]\n",
        "estimadores = [\n",
        "    ('Decision Tree', DecisionTreeClassifier()),\n",
        "    ('k-NN', KNeighborsClassifier()),\n",
        "    ('Naive Bayes', GaussianNB()),\n",
        "]\n",
        "\n",
        "# Dicionário para guardar resultados por max_features\n",
        "resultados_por_max_features = {\n",
        "    0.3: [],\n",
        "    0.5: [],\n",
        "    0.8: []\n",
        "}\n",
        "\n",
        "# Loop nos experimentos\n",
        "for nome_base, (X, y) in bases_normalizadas.items():\n",
        "    y = y.astype(str)\n",
        "\n",
        "    for nome_clf, clf in estimadores:\n",
        "        for max_feat in max_features_list:\n",
        "            for n in n_estimators_list:\n",
        "                model = BaggingClassifier(\n",
        "                    estimator=clf,\n",
        "                    n_estimators=n,\n",
        "                    max_features=max_feat,\n",
        "                    random_state=1\n",
        "                )\n",
        "\n",
        "                # 10-fold CV\n",
        "                acc_cv = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
        "                y_pred_cv = cross_val_predict(model, X, y, cv=10)\n",
        "                cm_cv = confusion_matrix(y, y_pred_cv)\n",
        "\n",
        "                # Hold-out 70/30\n",
        "                X_train, X_test, y_train, y_test = train_test_split(\n",
        "                    X, y, test_size=0.3, random_state=42, shuffle=True\n",
        "                )\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred_split = model.predict(X_test)\n",
        "                acc_split = accuracy_score(y_test, y_pred_split)\n",
        "                cm_split = confusion_matrix(y_test, y_pred_split)\n",
        "\n",
        "                # Armazena os resultados na lista correta\n",
        "                resultados_por_max_features[max_feat].append({\n",
        "                    'Base': nome_base,\n",
        "                    'Classificador': nome_clf,\n",
        "                    'n_estimators': n,\n",
        "                    'max_features': max_feat,\n",
        "                    'Acuracia_10fold': round(acc_cv.mean() * 100, 2),\n",
        "                    'Desvio_10fold': round(acc_cv.std() * 100, 2),\n",
        "                    'Matriz_Confusao_10fold': cm_cv.tolist(),\n",
        "                    'Acuracia_Split7030': round(acc_split * 100, 2),\n",
        "                    'Matriz_Confusao_Split7030': cm_split.tolist()\n",
        "                })\n",
        "\n",
        "# Exportar para 3 arquivos CSV separados\n",
        "for max_feat, resultados in resultados_por_max_features.items():\n",
        "    df = pd.DataFrame(resultados)\n",
        "    nome_arquivo = f'Resultados_Bagging_FeatureSelection_maxfeat{str(max_feat).replace(\".\", \"\")}.csv'\n",
        "    df.to_csv(nome_arquivo, index=False)\n",
        "    print(f\"✅ CSV salvo: {nome_arquivo}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpWoDgdwQW4z",
        "outputId": "325ca290-e923-4d16-b03c-4b48dcd6f2b9"
      },
      "id": "NpWoDgdwQW4z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV salvo: Resultados_Bagging_FeatureSelection_maxfeat03.csv\n",
            "✅ CSV salvo: Resultados_Bagging_FeatureSelection_maxfeat05.csv\n",
            "✅ CSV salvo: Resultados_Bagging_FeatureSelection_maxfeat08.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2552be3",
      "metadata": {
        "id": "b2552be3"
      },
      "source": [
        "# 🔷 BOOSTING Experimentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85d85ea6",
      "metadata": {
        "id": "85d85ea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704c7b82-6305-4df4-88e9-1d38fe05ab8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Resultados salvos em 'Resultados_Boosting_Holdout_e_KFold.csv'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "\n",
        "# Lista para armazenar resultados\n",
        "boosting_resultados = []\n",
        "\n",
        "# Classificadores a testar com AdaBoost\n",
        "estimadores = [\n",
        "    ('AD', DecisionTreeClassifier()),\n",
        "    ('NB', GaussianNB())\n",
        "]\n",
        "\n",
        "# Loop nas bases e parâmetros\n",
        "for nome_base, (X, y) in bases_normalizadas.items():\n",
        "    y = y.astype(str)  # Evita erro com tipos mistos\n",
        "\n",
        "    for nome_clf, clf in estimadores:\n",
        "        for n in [10, 20, 30]:\n",
        "            model = AdaBoostClassifier(estimator=clf, n_estimators=n, random_state=1)\n",
        "\n",
        "            # 🔁 10-fold cross-validation\n",
        "            acc_cv = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
        "            y_pred_cv = cross_val_predict(model, X, y, cv=10)\n",
        "            cm_cv = confusion_matrix(y, y_pred_cv)\n",
        "\n",
        "            # 🎯 Hold-out (70/30)\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, shuffle=True)\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred_split = model.predict(X_test)\n",
        "            acc_split = accuracy_score(y_test, y_pred_split)\n",
        "            cm_split = confusion_matrix(y_test, y_pred_split)\n",
        "\n",
        "            # Salvar resultado\n",
        "            boosting_resultados.append({\n",
        "                'Base': nome_base,\n",
        "                'Classificador': nome_clf,\n",
        "                'n_estimators': n,\n",
        "                'Acuracia_10fold': round(np.mean(acc_cv) * 100, 2),\n",
        "                'Desvio_10fold': round(np.std(acc_cv) * 100, 2),\n",
        "                'Matriz_Confusao_10fold': cm_cv.tolist(),\n",
        "                'Acuracia_Split7030': round(acc_split * 100, 2),\n",
        "                'Matriz_Confusao_Split7030': cm_split.tolist()\n",
        "            })\n",
        "\n",
        "# Exportar para CSV\n",
        "df_resultados = pd.DataFrame(boosting_resultados)\n",
        "df_resultados.to_csv('Resultados_Boosting_Holdout_e_KFold.csv', index=False)\n",
        "\n",
        "print(\"✅ Resultados salvos em 'Resultados_Boosting_Holdout_e_KFold.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ad696b2",
      "metadata": {
        "id": "1ad696b2"
      },
      "outputs": [],
      "source": [
        "## Carregando o Bagging e os algoritmos base (DT), (MLP), (k-NN) e (NB)\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91331889",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91331889",
        "outputId": "4fd98c5e-30a4-4c5e-dde7-5b4f724cf8c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.693\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[116,  30],\n",
              "       [ 41,  44]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Preparando Hold-out de 70/30\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 70% training and 30% test\n",
        "X_train_70, X_test_30, y_train_70, y_test_30 = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "## Instanciando Boosting com DecisionTree\n",
        "adaclassifier = AdaBoostClassifier(estimator=DecisionTreeClassifier(),\n",
        "                                   n_estimators=10,learning_rate=1.0)\n",
        "\n",
        "adaclassifier.fit(X_train_70,y_train_70)\n",
        "y_pred = adaclassifier.predict(X_test_30)\n",
        "\n",
        "## Model Accuracy\n",
        "acuracia = metrics.accuracy_score(y_test_30, y_pred)\n",
        "print('Accuracy: %.3f' % acuracia)\n",
        "\n",
        "# Matriz de confusão p/ 30%\n",
        "confusion_matrix(y_test_30, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa6d4d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aa6d4d4",
        "outputId": "96c2fa40-9e3f-47ed-fe06-141ebb4af271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.698 (0.067)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[378, 122],\n",
              "       [111, 157]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Preparando 10-fold CV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "# 10-fold CV\n",
        "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "## Instanciando Boosting com DecisionTree\n",
        "adaclassifier = AdaBoostClassifier(estimator=DecisionTreeClassifier(),\n",
        "                                   n_estimators=10,learning_rate=1.0)\n",
        "\n",
        "# Model Accuracy\n",
        "scores = cross_val_score(adaclassifier, X, y, scoring='accuracy', cv=kf)\n",
        "print('Accuracy: %.3f (%.3f)' % (scores.mean(), scores.std()))\n",
        "\n",
        "# Matriz de confusão p/ k fold\n",
        "y_pred = cross_val_predict(adaclassifier, X, y, cv=kf)\n",
        "confusion_matrix(y, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f021555",
      "metadata": {
        "id": "9f021555"
      },
      "source": [
        "# 🔷 RANDOMFOREST Experimentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a0ab921",
      "metadata": {
        "id": "5a0ab921"
      },
      "outputs": [],
      "source": [
        "## Carregando o Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba8c5cf6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba8c5cf6",
        "outputId": "e08fc2bf-574f-4f01-a245-9f0fabe383f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Resultados salvos em 'Resultados_RandomForest_Colab.csv'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Substitua isso pela sua estrutura de dados já normalizada\n",
        "# Exemplo:\n",
        "# bases_normalizadas = {\n",
        "#     'VGG19_256_MAX': (X1, y1),\n",
        "#     'VGG19_256_MAX_PCA': (X2, y2),\n",
        "# }\n",
        "\n",
        "# Parâmetros\n",
        "criterios = ['gini', 'entropy', 'log_loss']\n",
        "n_estimators_list = [10, 20, 30, 100]\n",
        "\n",
        "# Lista para armazenar os resultados\n",
        "resultados_rf = []\n",
        "\n",
        "# Loop pelas bases normalizadas\n",
        "for nome_base, (X, y) in bases_normalizadas.items():\n",
        "    y = y.astype(str)  # prevenir erros de tipo\n",
        "\n",
        "    for criterio in criterios:\n",
        "        linha_resultado = {\n",
        "            'Base': nome_base,\n",
        "            'Criterio': criterio\n",
        "        }\n",
        "\n",
        "        accs = []\n",
        "\n",
        "        for n_estimators in n_estimators_list:\n",
        "            model = RandomForestClassifier(\n",
        "                n_estimators=n_estimators,\n",
        "                criterion=criterio,\n",
        "                random_state=42\n",
        "            )\n",
        "            scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
        "            media = round(scores.mean() * 100, 2)\n",
        "            desvio = round(scores.std() * 100, 2)\n",
        "            linha_resultado[f'Acc_{n_estimators}'] = media\n",
        "            accs.append(media)\n",
        "\n",
        "        linha_resultado['Media_Acc'] = round(np.mean(accs), 2)\n",
        "        resultados_rf.append(linha_resultado)\n",
        "\n",
        "# Gerar DataFrame final\n",
        "df_rf = pd.DataFrame(resultados_rf)\n",
        "\n",
        "# Salvar como CSV\n",
        "df_rf.to_csv('Resultados_RandomForest_Colab.csv', index=False)\n",
        "print(\"✅ Resultados salvos em 'Resultados_RandomForest_Colab.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8ee5684",
      "metadata": {
        "id": "c8ee5684"
      },
      "source": [
        "# 🧠 Stacking Classifier (Heterogêneo)\n",
        "Executa comitês de stacking combinando diferentes classificadores base.\n",
        "Variações: 5, 10, 15, 20 classificadores com `VotingClassifier` ou `StackingClassifier`.\n",
        "\n",
        "A base final de decisão pode ser uma árvore, MLP ou regressão logística."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3817a96",
      "metadata": {
        "id": "d3817a96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd00043-b2c3-44fb-afda-310478f06565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Resultados salvos em 'Resultados_Stacking_Colab.csv'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Substitua com suas bases normalizadas\n",
        "# Exemplo:\n",
        "# bases_normalizadas = {\n",
        "#     'VGG19_256_MAX': (X1, y1),\n",
        "#     'VGG19_256_MAX_PCA': (X2, y2),\n",
        "# }\n",
        "\n",
        "# Classificadores base a serem usados no Stacking\n",
        "modelos_base = [\n",
        "    ('knn', KNeighborsClassifier()),\n",
        "    ('dt', DecisionTreeClassifier()),\n",
        "    ('nb', GaussianNB())\n",
        "]\n",
        "\n",
        "# Número de classificadores no stacking\n",
        "quantidades = [5, 10, 15, 20]\n",
        "\n",
        "# Lista para armazenar os resultados\n",
        "resultados_stacking = []\n",
        "\n",
        "for nome_base, (X, y) in bases_normalizadas.items():\n",
        "    y = y.astype(str)  # Evitar erro com tipos mistos\n",
        "\n",
        "    for qnt in quantidades:\n",
        "        # Repete os modelos até atingir a quantidade desejada\n",
        "        estimadores = [\n",
        "            (f'{nome}_{i}', clf)\n",
        "            for i, (nome, clf) in enumerate(modelos_base * ((qnt // len(modelos_base)) + 1))\n",
        "        ][:qnt]\n",
        "\n",
        "        # Define o stacking\n",
        "        stacking = StackingClassifier(\n",
        "            estimators=estimadores,\n",
        "            final_estimator=LogisticRegression(),\n",
        "            cv=10\n",
        "        )\n",
        "\n",
        "        # Avaliação com 10-fold\n",
        "        scores = cross_val_score(stacking, X, y, cv=10, scoring='accuracy')\n",
        "\n",
        "        resultados_stacking.append({\n",
        "            'Base': nome_base,\n",
        "            'Classificadores_Base': qnt,\n",
        "            'Acuracia_Media': round(scores.mean() * 100, 2),\n",
        "            'Desvio_Padrao': round(scores.std() * 100, 2)\n",
        "        })\n",
        "\n",
        "# Gerar DataFrame final e salvar\n",
        "df_stacking = pd.DataFrame(resultados_stacking)\n",
        "df_stacking.to_csv('Resultados_Stacking_Colab.csv', index=False)\n",
        "print(\"✅ Resultados salvos em 'Resultados_Stacking_Colab.csv'\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3501ff6d",
        "9f021555",
        "c8ee5684",
        "002a7570"
      ],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}