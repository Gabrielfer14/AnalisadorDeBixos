{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-Tv28FPAXSZ",
        "outputId": "f4ea7759-7b9c-4bd4-991c-3cc33b44e7c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GaussianNB     | VGG16_256_AVG.csv              → 95.12% ± 1.89%\n",
            "MultinomialNB  | VGG16_256_AVG.csv              → 97.50% ± 2.09%\n",
            "ComplementNB   | VGG16_256_AVG.csv              → 97.38% ± 1.97%\n",
            "GaussianNB     | VGG16_256_MAX.csv              → 97.25% ± 2.22%\n",
            "MultinomialNB  | VGG16_256_MAX.csv              → 98.12% ± 1.51%\n",
            "ComplementNB   | VGG16_256_MAX.csv              → 97.75% ± 1.56%\n",
            "GaussianNB     | VGG19_128_AVG.csv              → 91.25% ± 1.48%\n",
            "MultinomialNB  | VGG19_128_AVG.csv              → 94.75% ± 2.89%\n",
            "ComplementNB   | VGG19_128_AVG.csv              → 92.88% ± 2.50%\n",
            "GaussianNB     | VGG19_128_MAX.csv              → 94.00% ± 2.22%\n",
            "MultinomialNB  | VGG19_128_MAX.csv              → 94.88% ± 2.34%\n",
            "ComplementNB   | VGG19_128_MAX.csv              → 92.50% ± 2.90%\n",
            "GaussianNB     | VGG19_256_AVG.csv              → 95.75% ± 1.70%\n",
            "MultinomialNB  | VGG19_256_AVG.csv              → 98.00% ± 1.87%\n",
            "ComplementNB   | VGG19_256_AVG.csv              → 97.25% ± 2.29%\n",
            "GaussianNB     | VGG19_256_MAX.csv              → 97.50% ± 1.48%\n",
            "MultinomialNB  | VGG19_256_MAX.csv              → 98.12% ± 1.15%\n",
            "ComplementNB   | VGG19_256_MAX.csv              → 97.75% ± 1.35%\n",
            "GaussianNB     | VGG16_256_AVG_PCA.csv          → 96.38% ± 2.53%\n",
            "MultinomialNB  | VGG16_256_AVG_PCA.csv          → 94.38% ± 2.25%\n",
            "ComplementNB   | VGG16_256_AVG_PCA.csv          → 95.00% ± 2.02%\n",
            "GaussianNB     | VGG16_256_MAX_PCA.csv          → 97.37% ± 2.05%\n",
            "MultinomialNB  | VGG16_256_MAX_PCA.csv          → 98.00% ± 1.39%\n",
            "ComplementNB   | VGG16_256_MAX_PCA.csv          → 97.12% ± 1.68%\n",
            "GaussianNB     | VGG19_128_AVG_PCA.csv          → 91.62% ± 2.50%\n",
            "MultinomialNB  | VGG19_128_AVG_PCA.csv          → 94.12% ± 2.80%\n",
            "ComplementNB   | VGG19_128_AVG_PCA.csv          → 91.63% ± 3.40%\n",
            "GaussianNB     | VGG19_128_MAX_PCA.csv          → 93.62% ± 2.65%\n",
            "MultinomialNB  | VGG19_128_MAX_PCA.csv          → 93.88% ± 3.85%\n",
            "ComplementNB   | VGG19_128_MAX_PCA.csv          → 90.38% ± 2.62%\n",
            "GaussianNB     | VGG19_256_AVG_PCA.csv          → 96.88% ± 1.87%\n",
            "MultinomialNB  | VGG19_256_AVG_PCA.csv          → 93.75% ± 1.85%\n",
            "ComplementNB   | VGG19_256_AVG_PCA.csv          → 95.13% ± 1.89%\n",
            "GaussianNB     | VGG19_256_MAX_PCA.csv          → 97.75% ± 1.75%\n",
            "MultinomialNB  | VGG19_256_MAX_PCA.csv          → 97.50% ± 1.68%\n",
            "ComplementNB   | VGG19_256_MAX_PCA.csv          → 96.25% ± 1.85%\n",
            "\n",
            "✅ CSV salvo como resultados_NaiveBayes_kfold.csv\n",
            "✅ Matrizes de confusão salvas em matrizesConfusao_NB_kfold.txt\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
        "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# ▶︎ Bases a processar\n",
        "arquivos_dataset = [\n",
        "    'VGG16_256_AVG.csv',  'VGG16_256_MAX.csv',\n",
        "    'VGG19_128_AVG.csv',  'VGG19_128_MAX.csv',\n",
        "    'VGG19_256_AVG.csv',  'VGG19_256_MAX.csv',\n",
        "    'VGG16_256_AVG_PCA.csv', 'VGG16_256_MAX_PCA.csv',\n",
        "    'VGG19_128_AVG_PCA.csv', 'VGG19_128_MAX_PCA.csv',\n",
        "    'VGG19_256_AVG_PCA.csv', 'VGG19_256_MAX_PCA.csv'\n",
        "]\n",
        "\n",
        "tipos_numericos = ['int32','int64','float16','float32','float64']\n",
        "\n",
        "# Classificadores Naive Bayes\n",
        "classificadores = {\n",
        "    'GaussianNB'    : GaussianNB(),\n",
        "    'MultinomialNB' : MultinomialNB(),\n",
        "    'ComplementNB'  : ComplementNB()\n",
        "}\n",
        "\n",
        "resultados = []\n",
        "mc_dict = {}\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "for arquivo in arquivos_dataset:\n",
        "    try:\n",
        "        df = pd.read_csv(arquivo, encoding='utf-8')\n",
        "    except FileNotFoundError:\n",
        "        print(f'⚠️  Arquivo não encontrado: {arquivo}')\n",
        "        continue\n",
        "\n",
        "    if 'classe' not in df.columns:\n",
        "        print(f'⚠️  Coluna \"classe\" ausente em {arquivo}')\n",
        "        continue\n",
        "\n",
        "    num_cols = list(df.select_dtypes(include=tipos_numericos).columns)\n",
        "    if not num_cols:\n",
        "        print(f'⚠️  Nenhum atributo numérico em {arquivo}')\n",
        "        continue\n",
        "\n",
        "    X_full = df[num_cols].copy()\n",
        "    y = df['classe']\n",
        "\n",
        "    for nome, clf in classificadores.items():\n",
        "        # Garantir valores ≥ 0 se necessário\n",
        "        if nome != 'GaussianNB':\n",
        "            X_mod = X_full.copy()\n",
        "            min_val = X_mod.min().min()\n",
        "            if min_val < 0:\n",
        "                shift = abs(min_val)\n",
        "                X_mod += shift\n",
        "        else:\n",
        "            X_mod = X_full\n",
        "\n",
        "        # Acurácia via cross_val_score\n",
        "        scores = cross_val_score(clf, X_mod, y, scoring='accuracy', cv=kf)\n",
        "        media = round(scores.mean() * 100, 2)\n",
        "        desvio = round(scores.std() * 100, 2)\n",
        "\n",
        "        # Matriz de confusão via cross_val_predict\n",
        "        y_pred = cross_val_predict(clf, X_mod, y, cv=kf)\n",
        "        cm = confusion_matrix(y, y_pred)\n",
        "        mc_dict[(arquivo, nome)] = cm\n",
        "\n",
        "        resultados.append({\n",
        "            'Classificador' : nome,\n",
        "            'Base'          : arquivo,\n",
        "            'Acuracia_%'    : media,\n",
        "            'Desvio_%'      : desvio\n",
        "        })\n",
        "\n",
        "        print(f'{nome:<14} | {arquivo:<30} → {media:.2f}% ± {desvio:.2f}%')\n",
        "\n",
        "# ▶︎ Salvar CSV ordenado\n",
        "df_res = pd.DataFrame(resultados)\n",
        "df_res = df_res.sort_values(by=['Classificador', 'Base'])\n",
        "df_res.to_csv('resultados_NaiveBayes_kfold.csv', index=False)\n",
        "print('\\n✅ CSV salvo como resultados_NaiveBayes_kfold.csv')\n",
        "\n",
        "# ▶︎ Salvar matrizes de confusão\n",
        "with open('matrizesConfusao_NB_kfold.txt', 'w') as f:\n",
        "    for (base, nome), cm in mc_dict.items():\n",
        "        f.write(f'\\nBase: {base} | {nome}\\n')\n",
        "        f.write(np.array2string(cm))\n",
        "        f.write('\\n')\n",
        "print('✅ Matrizes de confusão salvas em matrizesConfusao_NB_kfold.txt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "kfold"
      ],
      "metadata": {
        "id": "5rwyCnr2CghK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ▶︎ Bases a processar\n",
        "arquivos_dataset = [\n",
        "    'VGG16_256_AVG.csv',\n",
        "    'VGG16_256_MAX.csv',\n",
        "    'VGG19_128_AVG.csv',\n",
        "    'VGG19_128_MAX.csv',\n",
        "    'VGG19_256_AVG.csv',\n",
        "    'VGG19_256_MAX.csv',\n",
        "    'VGG16_256_AVG_PCA.csv',\n",
        "    'VGG16_256_MAX_PCA.csv',\n",
        "    'VGG19_128_AVG_PCA.csv',\n",
        "    'VGG19_128_MAX_PCA.csv',\n",
        "    'VGG19_256_AVG_PCA.csv',\n",
        "    'VGG19_256_MAX_PCA.csv'\n",
        "]\n",
        "\n",
        "tipos_numericos = ['int32', 'int64', 'float16', 'float32', 'float64']\n",
        "\n",
        "# Lista para armazenar os resultados de cada base\n",
        "resultados_kfold = []\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "# We don't need train_test_split, metrics, confusion_matrix, cross_val_predict for this version\n",
        "\n",
        "# Loop sobre cada arquivo na lista\n",
        "for arquivo in arquivos_dataset:\n",
        "    print(f\"Processando a base: {arquivo}\")\n",
        "\n",
        "    # Carregar o dataset\n",
        "    try:\n",
        "        dataset = pd.read_csv(arquivo)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: O arquivo {arquivo} não foi encontrado. Pulando para o próximo.\")\n",
        "        continue # Pula para o próximo arquivo se este não for encontrado\n",
        "\n",
        "    # Selecionar colunas numéricas e a coluna de classe\n",
        "    cols_num = dataset.select_dtypes(include=tipos_numericos)\n",
        "    colunas_numericas = list(cols_num.columns)\n",
        "\n",
        "    # Verificar se a coluna 'classe' existe e se há colunas numéricas\n",
        "    if 'classe' not in dataset.columns:\n",
        "        print(f\"Aviso: O arquivo {arquivo} não contém a coluna 'classe'. Pulando para o próximo.\")\n",
        "        continue\n",
        "    if not colunas_numericas:\n",
        "        print(f\"Aviso: O arquivo {arquivo} não contém colunas numéricas dos tipos especificados. Pulando para o próximo.\")\n",
        "        continue\n",
        "\n",
        "    # Separate features (x) and target (y)\n",
        "    x = dataset[colunas_numericas]\n",
        "    y = dataset['classe']\n",
        "\n",
        "    ## K-Fold Cross-Validation\n",
        "    kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "    gnb_kfold = GaussianNB()\n",
        "\n",
        "    # Perform cross-validation and get accuracy scores for each fold\n",
        "    scores_kfold = cross_val_score(gnb_kfold, x, y, scoring = 'accuracy', cv = kf)\n",
        "\n",
        "    # Calculate the mean accuracy across the folds\n",
        "    acuracia_kfold_mean = scores_kfold.mean()\n",
        "\n",
        "    print(f\"Acurácia K-Fold (média) para {arquivo}: {acuracia_kfold_mean:.3f}\")\n",
        "\n",
        "    # Store the K-Fold results\n",
        "    resultados_kfold.append({\n",
        "        'Base de Dados': arquivo,\n",
        "        'Acurácia (K-Fold Média)': acuracia_kfold_mean\n",
        "    })\n",
        "\n",
        "\n",
        "# Save the results to a CSV file\n",
        "df_resultados_kfold = pd.DataFrame(resultados_kfold)\n",
        "df_resultados_kfold.to_csv('resultados_naive_bayes_kfold.csv', index=False)\n",
        "\n",
        "print(\"Processamento concluído. Resultados salvos em 'resultados_naive_bayes_kfold.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65LHn90vCilS",
        "outputId": "571a66a3-546c-4098-b965-0b641dc240b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando a base: VGG16_256_AVG.csv\n",
            "Acurácia K-Fold (média) para VGG16_256_AVG.csv: 0.951\n",
            "Processando a base: VGG16_256_MAX.csv\n",
            "Acurácia K-Fold (média) para VGG16_256_MAX.csv: 0.972\n",
            "Processando a base: VGG19_128_AVG.csv\n",
            "Acurácia K-Fold (média) para VGG19_128_AVG.csv: 0.912\n",
            "Processando a base: VGG19_128_MAX.csv\n",
            "Acurácia K-Fold (média) para VGG19_128_MAX.csv: 0.940\n",
            "Processando a base: VGG19_256_AVG.csv\n",
            "Acurácia K-Fold (média) para VGG19_256_AVG.csv: 0.957\n",
            "Processando a base: VGG19_256_MAX.csv\n",
            "Acurácia K-Fold (média) para VGG19_256_MAX.csv: 0.975\n",
            "Processando a base: VGG16_256_AVG_PCA.csv\n",
            "Acurácia K-Fold (média) para VGG16_256_AVG_PCA.csv: 0.964\n",
            "Processando a base: VGG16_256_MAX_PCA.csv\n",
            "Acurácia K-Fold (média) para VGG16_256_MAX_PCA.csv: 0.974\n",
            "Processando a base: VGG19_128_AVG_PCA.csv\n",
            "Acurácia K-Fold (média) para VGG19_128_AVG_PCA.csv: 0.916\n",
            "Processando a base: VGG19_128_MAX_PCA.csv\n",
            "Acurácia K-Fold (média) para VGG19_128_MAX_PCA.csv: 0.936\n",
            "Processando a base: VGG19_256_AVG_PCA.csv\n",
            "Acurácia K-Fold (média) para VGG19_256_AVG_PCA.csv: 0.969\n",
            "Processando a base: VGG19_256_MAX_PCA.csv\n",
            "Acurácia K-Fold (média) para VGG19_256_MAX_PCA.csv: 0.978\n",
            "Processamento concluído. Resultados salvos em 'resultados_naive_bayes_kfold.csv'\n"
          ]
        }
      ]
    }
  ]
}